import torch
import torch.nn as nn

# Define a simple MLP
class MLP(nn.Module):
    def __init__(self):
        super(MLP, self).__init__()
        self.fc1 = nn.Linear(4, 3)  # Input: 4 features, Output: 3 features
        self.fc2 = nn.Linear(3, 2)  # Input: 3 features, Output: 2 features

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# Instantiate the model
model = MLP()

# Predefined weights and biases for each layer
predefined_weights_fc1 = torch.tensor([[0.1, 0.2, 0.3, 0.4],
                                       [0.5, 0.6, 0.7, 0.8],
                                       [0.9, 1.0, 1.1, 1.2]])
predefined_biases_fc1 = torch.tensor([0.1, 0.2, 0.3])

predefined_weights_fc2 = torch.tensor([[0.1, 0.2, 0.3],
                                       [0.4, 0.5, 0.6]])
predefined_biases_fc2 = torch.tensor([0.4, 0.5])

# Assign the predefined weights and biases
with torch.no_grad():  # Disable gradient tracking while modifying weights
    model.fc1.weight.copy_(predefined_weights_fc1)
    model.fc1.bias.copy_(predefined_biases_fc1)
    model.fc2.weight.copy_(predefined_weights_fc2)
    model.fc2.bias.copy_(predefined_biases_fc2)

# Verify the assignment
print("FC1 Weights:\n", model.fc1.weight)
print("FC1 Biases:\n", model.fc1.bias)
print("FC2 Weights:\n", model.fc2.weight)
print("FC2 Biases:\n", model.fc2.bias)

# Test the model with some input
input_data = torch.tensor([[1.0, 2.0, 3.0, 4.0]])
output = model(input_data)
print("Output:\n", output)