#include <iostream>
#include <cmath>
#include <cstdlib>

__global__ void softmax(float *input, float *output, int N) {
    // Shared memory to store intermediate values for the block
    __shared__ float shared_max;
    __shared__ float shared_sum;

    // Calculate the thread ID
    int tid = threadIdx.x;

    // Step 1: Find the maximum value in the input for numerical stability
    float local_max = -FLT_MAX;
    for (int i = tid; i < N; i += blockDim.x) {
        local_max = fmaxf(local_max, input[i]);
    }

    // Reduce local_max to shared_max
    atomicMax((int*)&shared_max, __float_as_int(local_max));
    __syncthreads();

    // Step 2: Compute the exponential values and their sum
    float local_sum = 0.0f;
    for (int i = tid; i < N; i += blockDim.x) {
        local_sum += expf(input[i] - shared_max);
    }

    // Reduce local_sum to shared_sum
    atomicAdd(&shared_sum, local_sum);
    __syncthreads();

    // Step 3: Compute the softmax output
    for (int i = tid; i < N; i += blockDim.x) {
        output[i] = expf(input[i] - shared_max) / shared_sum;
    }
}

// Host code to launch the kernel
void launch_softmax_kernel(float *input, float *output, int N) {
    dim3 gridSize(1, 1, 1);
    dim3 blockSize(64, 1, 1);

    // Allocate device memory
    float *d_input, *d_output;
    cudaMalloc(&d_input, N * sizeof(float));
    cudaMalloc(&d_output, N * sizeof(float));

    // Copy input data to device
    cudaMemcpy(d_input, input, N * sizeof(float), cudaMemcpyHostToDevice);

    // Launch the kernel
    softmax<<<gridSize, blockSize>>>(d_input, d_output, N);

    // Copy output data back to host
    cudaMemcpy(output, d_output, N * sizeof(float), cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_input);
    cudaFree(d_output);
}

int main() {
    const int N = 100;
    float input[N], output[N];

    // Generate random input values
    std::srand(42); // Seed for reproducibility
    for (int i = 0; i < N; i++) {
        input[i] = static_cast<float>(std::rand() % 100) / 10.0f; // Random float between 0 and 10
    }

    // Print the input values
    std::cout << "Input values:\n";
    for (int i = 0; i < N; i++) {
        std::cout << input[i] << " ";
    }
    std::cout << "\n";

    // Launch the softmax kernel
    launch_softmax_kernel(input, output, N);

    // Print the output values
    std::cout << "Softmax output:\n";
    for (int i = 0; i < N; i++) {
        std::cout << output[i] << " ";
    }
    std::cout << "\n";

    return 0;
}
