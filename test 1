#include <iostream>
#include <curand_kernel.h>
#include <cuda_fp16.h>

#define INPUT_SIZE 100
#define HIDDEN_SIZE 200
#define OUTPUT_SIZE 100
#define BLOCK_SIZE 256

// CUDA kernel to initialize random weights and biases
__global__ void initialize_weights(float16 *weights1, float16 *bias1, float16 *weights2, float16 *bias2, int input_size, int hidden_size, int output_size, unsigned long long seed) {
    int idx = threadIdx.x + blockIdx.x * blockDim.x;

    curandState state;
    curand_init(seed, idx, 0, &state);

    if (idx < hidden_size * input_size) {
        weights1[idx] = __float2half(curand_uniform(&state) * 0.1f);  // Initialize weights between layers
    }

    if (idx < hidden_size) {
        bias1[idx] = __float2half(curand_uniform(&state) * 0.1f);  // Initialize hidden layer biases
    }

    if (idx < output_size * hidden_size) {
        weights2[idx] = __float2half(curand_uniform(&state) * 0.1f);  // Initialize output layer weights
    }

    if (idx < output_size) {
        bias2[idx] = __float2half(curand_uniform(&state) * 0.1f);  // Initialize output layer biases
    }
}

// CUDA kernel for forward pass
__global__ void forward_pass(float16 *input, float16 *weights1, float16 *bias1, float16 *weights2, float16 *bias2, float16 *output, int input_size, int hidden_size, int output_size) {
    int idx = threadIdx.x + blockIdx.x * blockDim.x;

    // Allocate memory for hidden layer activations
    __shared__ float16 hidden[HIDDEN_SIZE];

    if (idx < hidden_size) {
        float16 sum = __float2half(0.0f);
        for (int i = 0; i < input_size; ++i) {
            sum = __hfma(input[i], weights1[i + idx * input_size], sum);  // Matrix-vector multiplication for hidden layer
        }
        hidden[idx] = __hadd(sum, bias1[idx]);  // Add bias
    }

    __syncthreads();

    if (idx < output_size) {
        float16 sum = __float2half(0.0f);
        for (int i = 0; i < hidden_size; ++i) {
            sum = __hfma(hidden[i], weights2[i + idx * hidden_size], sum);  // Matrix-vector multiplication for output layer
        }
        sum = __hadd(sum, bias2[idx]);  // Add bias
        output[idx] = sum;
    }
}

// CUDA kernel for softmax activation
__global__ void softmax(float16 *output, float16 *result, int output_size) {
    int idx = threadIdx.x + blockIdx.x * blockDim.x;

    if (idx < output_size) {
        float16 max_val = output[0];
        for (int i = 1; i < output_size; ++i) {
            max_val = __hmax(max_val, output[i]);
        }

        float16 sum_exp = __float2half(0.0f);
        for (int i = 0; i < output_size; ++i) {
            sum_exp = __hadd(sum_exp, __expf(output[i] - max_val));  // Sum of exponentiated outputs
        }

        result[idx] = __expf(output[idx] - max_val) / sum_exp;  // Softmax output
    }
}

int main() {
    float16 *d_input, *d_weights1, *d_bias1, *d_weights2, *d_bias2, *d_output, *d_result;
    int input_size = INPUT_SIZE;
    int hidden_size = HIDDEN_SIZE;
    int output_size = OUTPUT_SIZE;

    // Allocate device memory
    cudaMalloc(&d_input, input_size * sizeof(float16));
    cudaMalloc(&d_weights1, hidden_size * input_size * sizeof(float16));
    cudaMalloc(&d_bias1, hidden_size * sizeof(float16));
    cudaMalloc(&d_weights2, output_size * hidden_size * sizeof(float16));
    cudaMalloc(&d_bias2, output_size * sizeof(float16));
    cudaMalloc(&d_output, output_size * sizeof(float16));
    cudaMalloc(&d_result, output_size * sizeof(float16));

    // Generate random input vector (100 random values)
    float16 *h_input = new float16[input_size];
    for (int i = 0; i < input_size; ++i) {
        h_input[i] = __float2half(rand() / (RAND_MAX + 1.0f));  // Random number in range [0, 1]
    }

    cudaMemcpy(d_input, h_input, input_size * sizeof(float16), cudaMemcpyHostToDevice);

    // Launch kernel to initialize weights and biases
    initialize_weights<<<(hidden_size * input_size + BLOCK_SIZE - 1) / BLOCK_SIZE, BLOCK_SIZE>>>(d_weights1, d_bias1, d_weights2, d_bias2, input_size, hidden_size, output_size, time(0));

    // Launch kernel for forward pass
    forward_pass<<<(output_size + BLOCK_SIZE - 1) / BLOCK_SIZE, BLOCK_SIZE>>>(d_input, d_weights1, d_bias1, d_weights2, d_bias2, d_output, input_size, hidden_size, output_size);

    // Launch kernel for softmax activation
    softmax<<<(output_size + BLOCK_SIZE - 1) / BLOCK_SIZE, BLOCK_SIZE>>>(d_output, d_result, output_size);

    // Copy result back to host
    float16 *h_result = new float16[output_size];
    cudaMemcpy(h_result, d_result, output_size * sizeof(float16), cudaMemcpyDeviceToHost);

    // Print the output (softmax result)
    std::cout << "Softmax Output: \n";
    for (int i = 0; i < output_size; ++i) {
        std::cout << __half2float(h_result[i]) << " ";
    }
    std::cout << std::endl;

    // Free allocated memory
    delete[] h_input;
    delete[] h_result;
    cudaFree(d_input);
    cudaFree(d_weights1);
    cudaFree(d_bias1);
    cudaFree(d_weights2);
    cudaFree(d_bias2);
    cudaFree(d_output);
    cudaFree(d_result);

    return 0;
}